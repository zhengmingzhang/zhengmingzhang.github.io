<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>使用AutoEncoder压缩人脸照片并生成人脸（pytorch）</title>
      <link href="/2020/04/13/autoencoder/"/>
      <url>/2020/04/13/autoencoder/</url>
      
        <content type="html"><![CDATA[<h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p><a href="https://github.com/zhengmingzhang/VAE_face" target="_blank" rel="noopener">AE_Face</a></p><h2 id="AutoEncoder简介"><a href="#AutoEncoder简介" class="headerlink" title="AutoEncoder简介"></a>AutoEncoder简介</h2><p><strong>autoencoder</strong>就是自动编码器，它的原理就不做介绍了网上有很多，简单的说就是一种自学习的无监督学习算法，它的输入与输出相同。我理解就是autoencoder能够学习数据的内部特征，因此这个算法常常被用来做数据降维、特征筛选和图像去噪音。我最开始接触到自动编码器是在ABB中国研究院实习的时候，当时带我的博士让我做一个基于机器学习的齿轮箱故障检测的项目，我就是用到了自动编码器来对震动数据的频谱进行降维。我的硕士论文也用到了autoencoder，说起来和这个算法还是有些缘分的。<br>最近working from home，看了蛮多的有趣的开源项目，发现autoencoder的应用还是非常广泛的，之前很火的DeepFake的基本原理竟然也是基于autoencoder，因此我想自己尝试训练一个autoencoder对人脸进行一个生成任务。下面我们从模型结构、数据加载、模型训练、生成结果四个部分来对其进行说明。</p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img src="model.png" alt="&quot;模型结构&quot;"><br>我做这个模型是预想能够用3个数字生成人脸的，因此encoder的结构设计成先使用卷积层与池化层先将3×60×60的图片编成32×15×15的特征图。之后经过四层fc层，输出神经元个数为3。decoder的目的是想将3个神经元恢复成原来的3×60×60的图像像素，因此设计了四层的fc，输出大小就是3×60×60。模型结构设计好后，就要编写前向传播的过程，我们输入整个autoencoder中的应该是batch_size×C×W×H的图像数据，首先经过encoder变成3,之后经过decoder进行恢复，注意经过卷积和池化层的特征图需要进行拉伸后放入fc层中，这个过程使用view()即能够实现。<br>整个模型的设计的代码如下，我们将模型设计和前向传播都封装进名为AutoEncoder的类中：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment" spellcheck="true"># 定义自编码器的网络结构</span><span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>AutoEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># self.encoder=nn.Sequential(     #->(3,60,60)</span>        <span class="token comment" spellcheck="true">###############################################################</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>                in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>                kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># ->(16,60,60)</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># ->(16,60,60)</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># ->(16,30,30)</span>        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># ->(16,48,48)</span>        <span class="token comment" spellcheck="true">###############################################################</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>  <span class="token comment" spellcheck="true"># ->(16,48,48)</span>                in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>                out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># ->(32,30,30)</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># ->(32,15,15)</span>        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">###############################################################</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">15</span> <span class="token operator">*</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 激活函数</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># )</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        encoded <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        decoded <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span>        <span class="token keyword">return</span> encoded<span class="token punctuation">,</span> decoded<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据载入"><a href="#数据载入" class="headerlink" title="数据载入"></a>数据载入</h2><p>用来训练的数据，我选择了CelebA人脸识别数据集，该数据集是由香港中文大学提供的，有20多万张人脸图片。由于我需要的模型要求不是很高，因此只用了其中5000张作为训练集。对于CelebA数据集的详细介绍可以参考：<br><a href="https://zhuanlan.zhihu.com/p/35975956" target="_blank" rel="noopener">CelebA</a><br>对数据集进行读取就比较简单，使用opencv就能够对图片进行读取并进行缩放，将每张图片都变成60×60的，得到图片的W×H×C的BGR结构，注意opencv读取的图片都是BGR，因此之后想要用显示图片时需要将BGR转为RGB才行。然后由于我们输入 网络中的图片默认应该是C×W×H的，因此之后我们还需要改变图片的维度。加载图片的代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载数据集</span><span class="token keyword">def</span> <span class="token function">getTrainData</span><span class="token punctuation">(</span>data_path<span class="token operator">=</span><span class="token string">"../celeba_select/"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    files <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>    imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 构造一个存放图片的列表数据结构</span>    <span class="token keyword">for</span> file <span class="token keyword">in</span> files<span class="token punctuation">:</span>        file_path <span class="token operator">=</span> data_path <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> file        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>        <span class="token keyword">if</span> img <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'错误! 无法在该地址找到图片!'</span><span class="token punctuation">)</span>        dim <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_AREA<span class="token punctuation">)</span>        imgs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token keyword">return</span> imgs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>对于autoencoder的训练，使用MSE loss来作为loss，也就是衡量经autoencoder输出的10800个特征点与与原图的10800特征点之间的拟合程度。这里需要注意的就是要将原图先转为tensor之后再由60×60×3变为10800，这样才能和autoencoder的输出一起计算MSE，并进行反向传播对模型进行训练。训练好的模型保存在autoencoder.pkl中。模型训练的代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> argparse<span class="token keyword">import</span> cv2<span class="token keyword">import</span> os<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">from</span> utils<span class="token punctuation">.</span>model <span class="token keyword">import</span> AutoEncoder<span class="token comment" spellcheck="true">#tb = SummaryWriter()</span><span class="token comment" spellcheck="true"># 训练并反向传播</span><span class="token keyword">def</span> <span class="token function">trainOneBatch</span><span class="token punctuation">(</span>batch<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">,</span> raw<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded<span class="token punctuation">,</span> decoded <span class="token operator">=</span> auto<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#tb.add_graph(auto, batch)</span>    loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>decoded<span class="token punctuation">,</span> raw<span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 前向传播获得误差</span><span class="token keyword">def</span> <span class="token function">testOneBatch</span><span class="token punctuation">(</span>batch<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">,</span> raw<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded<span class="token punctuation">,</span> decoded <span class="token operator">=</span> auto<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>    loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>decoded<span class="token punctuation">,</span> raw<span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token comment" spellcheck="true"># 加载数据集</span><span class="token keyword">def</span> <span class="token function">getTrainData</span><span class="token punctuation">(</span>data_path<span class="token operator">=</span><span class="token string">"./celeba_select/"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    files <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>    imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 构造一个存放图片的列表数据结构</span>    <span class="token keyword">for</span> file <span class="token keyword">in</span> files<span class="token punctuation">:</span>        file_path <span class="token operator">=</span> data_path <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> file        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>        <span class="token keyword">if</span> img <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'错误! 无法在该地址找到图片!'</span><span class="token punctuation">)</span>        dim <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_AREA<span class="token punctuation">)</span>        imgs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token keyword">return</span> imgs<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>float<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'lr'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batch_size'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'batch size'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epoch'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'epoch size'</span><span class="token punctuation">)</span>    opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 超参数</span>    LR <span class="token operator">=</span> opt<span class="token punctuation">.</span>lr    BATCH_SIZE <span class="token operator">=</span> opt<span class="token punctuation">.</span>batch_size    EPOCHES <span class="token operator">=</span> opt<span class="token punctuation">.</span>epoch    <span class="token comment" spellcheck="true"># 获取gpu是不是可用</span>    cuda_available <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 实例化网络</span>    auto <span class="token operator">=</span> AutoEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> cuda_available<span class="token punctuation">:</span>        auto<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 定义优化器和损失函数</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>auto<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 数据准备</span>    imgs <span class="token operator">=</span> getTrainData<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>EPOCHES<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 打乱数据</span>        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        count <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># count是为了凑齐成为一个batch_size的大小</span>        batch <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            img <span class="token operator">=</span> imgs<span class="token punctuation">[</span>j<span class="token punctuation">]</span>            count <span class="token operator">+=</span> <span class="token number">1</span>            batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>            <span class="token keyword">if</span> count <span class="token operator">==</span> BATCH_SIZE <span class="token operator">or</span> j <span class="token operator">==</span> len<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 列表转成张量，再转换维度</span>                batch_train <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>  <span class="token comment" spellcheck="true"># batch,3,60,60</span>                raw <span class="token operator">=</span> batch_train<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_train<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># batch,3*60*60</span>                <span class="token keyword">if</span> cuda_available<span class="token punctuation">:</span>                    raw <span class="token operator">=</span> raw<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 数据变换到gpu上</span>                    batch_train <span class="token operator">=</span> batch_train<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                trainOneBatch<span class="token punctuation">(</span>batch_train<span class="token punctuation">,</span> raw<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 训练一个批次</span>                batch<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>                count <span class="token operator">=</span> <span class="token number">0</span>        batch<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 测试</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>imgs<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>            batch_train <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>            raw <span class="token operator">=</span> batch_train<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_train<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> cuda_available<span class="token punctuation">:</span>                raw <span class="token operator">=</span> raw<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                batch_train <span class="token operator">=</span> batch_train<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 调用函数获得损失</span>        loss <span class="token operator">=</span> testOneBatch<span class="token punctuation">(</span>batch_train<span class="token punctuation">,</span> raw<span class="token punctuation">)</span>        batch<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#tb.add_scalar('Loss', loss, i)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 把训练的中间结果输出到本地文件</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>auto<span class="token punctuation">,</span> <span class="token string">"autoencoder.pkl"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型最终结果"><a href="#模型最终结果" class="headerlink" title="模型最终结果"></a>模型最终结果</h2><p>对于模型的应用，我想实现以下几个功能。<br>1.get_feature：输入一张图片，我们使用encoder将图片编码成3个数字。<br>2.invtrans：根据编码后的三个数字生成人脸<br>3.get_rand_face：随机生成人脸<br>代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> cv2<span class="token keyword">import</span> random<span class="token keyword">from</span> utils<span class="token punctuation">.</span>model <span class="token keyword">import</span> AutoEncoder<span class="token keyword">class</span> <span class="token class-name">face_AE</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>auto<span class="token punctuation">:</span> AutoEncoder <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"autoencoder.pkl"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">get_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        image <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>        <span class="token keyword">if</span> img <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'错误! 无法在该地址找到图片!'</span><span class="token punctuation">)</span>        dim <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_AREA<span class="token punctuation">)</span>        image<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        img <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>        <span class="token keyword">return</span> img    <span class="token keyword">def</span> <span class="token function">get_feature</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        encoded<span class="token punctuation">,</span> decoded <span class="token operator">=</span> self<span class="token punctuation">.</span>auto<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token keyword">return</span> encoded    <span class="token keyword">def</span> <span class="token function">invtrans</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">:</span>        feature <span class="token operator">=</span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>        img_re <span class="token operator">=</span> self<span class="token punctuation">.</span>auto<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>        img_re <span class="token operator">=</span> img_re<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">255</span>        cv2<span class="token punctuation">.</span>imwrite<span class="token punctuation">(</span><span class="token string">"imgs/"</span> <span class="token operator">+</span> <span class="token string">"im.jpg"</span><span class="token punctuation">,</span> img_re<span class="token punctuation">)</span>        <span class="token keyword">return</span> img_re    <span class="token keyword">def</span> <span class="token function">get_rand_face</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> length<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        random_feature <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>length<span class="token punctuation">)</span><span class="token punctuation">:</span>            feature <span class="token operator">=</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>            feature <span class="token operator">=</span> round<span class="token punctuation">(</span>feature<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>            random_feature<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>        random_feature <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>random_feature<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>invtrans<span class="token punctuation">(</span>random_feature<span class="token punctuation">)</span>        <span class="token keyword">return</span> random_feature<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    face <span class="token operator">=</span> face_AE<span class="token punctuation">(</span><span class="token punctuation">)</span>    img_path <span class="token operator">=</span> <span class="token string">"./celeba_select/000199.jpg"</span>    img <span class="token operator">=</span> face<span class="token punctuation">.</span>get_img<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    feature <span class="token operator">=</span> face<span class="token punctuation">.</span>get_feature<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    face<span class="token punctuation">.</span>invtrans<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>    face<span class="token punctuation">.</span>get_rand_face<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>展示下通过随机数产生的人脸图像<br><img src="1.jpg" alt> <img src="2.jpg" alt> <img src="3.jpg" alt> <img src="4.jpg" alt><br>emmm…..怎么说呢，随机数生成的人脸能看出是人脸的，感觉效果还行？<br>但是将原有图片先编码再解码出来的图片和与原来相差很大，而且生成的貌似都是女性的脸，这个问题还有待研究。</p><h2 id="2020-4-16更新"><a href="#2020-4-16更新" class="headerlink" title="2020.4.16更新"></a>2020.4.16更新</h2><p>最近研究了下其他人写的autoencoder，并且研究了下VAE，发现自己的模型结构设计的比较差，没有想到在decoder中使用反卷积操作。因此我将原来的AE模型结构改造成VAE，在VAE中encoder有两个，一个用来计算均值，一个用来计算方差。本质是在AE的基础上，对encoder的结果加上了一个高斯噪声，使得decoder的结果对于噪声的鲁棒性更好。VAE的示意图：<br><img src="VAE.png" alt="&quot;VAE&quot;"><br>对原先的模型结构进行了修改，修改model.py</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>AutoEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        latent_dim <span class="token operator">=</span> <span class="token number">128</span>        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        in_channels <span class="token operator">=</span> <span class="token number">3</span>        hidden_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Build Encoder</span>        <span class="token keyword">for</span> h_dim <span class="token keyword">in</span> hidden_dims<span class="token punctuation">:</span>            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token operator">=</span>h_dim<span class="token punctuation">,</span>                              kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>h_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                    nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>            in_channels <span class="token operator">=</span> h_dim        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc_mu <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc_var <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Build Decoder</span>        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>decoder_input <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 反转hidden_dims 这样是为了能够恢复成原来的图片size</span>        hidden_dims<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                    nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>                                       hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                                       stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>                                       padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                       output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 单独设置一个final_layer是为了对最后一层进行特殊处理</span>        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                               hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                               stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>                               padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                               output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                      kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Encodes the input by passing through the encoder network        and returns the latent codes.        :param input: (Tensor) Input tensor to encoder [N x C x H x W]        :return: (Tensor) List of latent codes        """</span>        result <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        result <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>result<span class="token punctuation">,</span> start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Split the result into mu and var components</span>        <span class="token comment" spellcheck="true"># of the latent Gaussian distribution</span>        mu <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_mu<span class="token punctuation">(</span>result<span class="token punctuation">)</span>        log_var <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_var<span class="token punctuation">(</span>result<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>mu<span class="token punctuation">,</span> log_var<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        result <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder_input<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        result <span class="token operator">=</span> result<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        result <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>result<span class="token punctuation">)</span>        result <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>result<span class="token punctuation">)</span>        <span class="token keyword">return</span> result    <span class="token keyword">def</span> <span class="token function">reparameterize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Will a single z be enough ti compute the expectation        for the loss??        :param mu: (Tensor) Mean of the latent Gaussian        :param logvar: (Tensor) Standard deviation of the latent Gaussian        :return:        """</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># multiply log variance with 0.5, then in-place exponent</span>            <span class="token comment" spellcheck="true"># yielding the standard deviation</span>            sample_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                std <span class="token operator">=</span> logvar<span class="token punctuation">.</span>mul<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>exp_<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># type: Variable</span>                eps <span class="token operator">=</span> Variable<span class="token punctuation">(</span>std<span class="token punctuation">.</span>data<span class="token punctuation">.</span>new<span class="token punctuation">(</span>std<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                sample_z<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eps<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>std<span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span>mu<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> sample_z        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> mu    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>reparameterize<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token keyword">for</span> z <span class="token keyword">in</span> z<span class="token punctuation">]</span><span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之后需要更改的一个非常重要的地方就是loss，之前在AE中，我是使用的MSE Loss,在VAE中设计了另外一种loss。VAE的LOSS由两部分组成。<br>1.<strong>BCE_LOSS</strong>：二分类交叉熵损失，用来衡量原图与生成的图片之间的像素误差<br>2.<strong>KLD_LOSS</strong>：KL散度，用来衡量潜在变量的分布与单位高斯分布之间的差异<br>VAE_LOSS = BCE_LOSS + KLD_LOSS</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>recon_x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># how well do input x and output recon_x agree?</span>    BCE <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> recon_x_one <span class="token keyword">in</span> recon_x<span class="token punctuation">:</span>        BCE <span class="token operator">+=</span> F<span class="token punctuation">.</span>binary_cross_entropy<span class="token punctuation">(</span>recon_x_one<span class="token punctuation">,</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    BCE <span class="token operator">/=</span> len<span class="token punctuation">(</span>recon_x<span class="token punctuation">)</span>    KLD <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> logvar <span class="token operator">-</span> mu<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">-</span> logvar<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    KLD <span class="token operator">/=</span> BATCH_SIZE <span class="token operator">*</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">64</span>    <span class="token keyword">return</span> BCE <span class="token operator">+</span> KLD<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>##查看结果</p>]]></content>
      
      
      <categories>
          
          <category> AI项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高效能人士的七个习惯</title>
      <link href="/2020/04/04/gao-xiao-neng-ren-shi-de-qi-ge-xi-guan/"/>
      <url>/2020/04/04/gao-xiao-neng-ren-shi-de-qi-ge-xi-guan/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img1.doubanio.com/view/thing_review/l/public/1942529.webp" alt="高效能人士的七个习惯示意图"></p><h2 id="习惯一：保持积极主动"><a href="#习惯一：保持积极主动" class="headerlink" title="习惯一：保持积极主动"></a>习惯一：<strong>保持积极主动</strong></h2><p>坚持以原则为中心的思维方式，关注于自己的“影响圈”，将自己的“影响圈不断扩大”。自己为自己的过去、现在及未来负责任，不要对环境、他人进行抱怨。</p><h2 id="习惯二：以终为始"><a href="#习惯二：以终为始" class="headerlink" title="习惯二：以终为始"></a>习惯二：<strong>以终为始</strong></h2><p>在做任何计划之前，都要在头脑中拟出愿景与目标，之后才是全心投注于自己的原则、价值观以及目标之上，进行实质的创造。</p><h2 id="习惯三：要事第一"><a href="#习惯三：要事第一" class="headerlink" title="习惯三：要事第一"></a>习惯三：<strong>要事第一</strong></h2><p>进行实质性的创造时，要将要事摆在第一位，不要被其他事项所打扰。做计划要做周计划，每周要做的事情要清楚，并且每天根据实际情况做调整。</p><h2 id="习惯四：双赢思维"><a href="#习惯四：双赢思维" class="headerlink" title="习惯四：双赢思维"></a>习惯四：<strong>双赢思维</strong></h2><p>禁止敌对式竞争，从互相依赖的角度来思考自己与家人、朋友、同事甚至竞争对手之间的关系。对于一个问题一定要优先找到互惠的解决办法。</p><h2 id="习惯五：知彼解己"><a href="#习惯五：知彼解己" class="headerlink" title="习惯五：知彼解己"></a>习惯五：<strong>知彼解己</strong></h2><p>有效沟通的关键永远都是：<strong><em>首先寻求去了解对方，让对方能够感受到你的真诚并且敞开心扉，之后再争取让对方了解自己</em></strong></p><h2 id="习惯六：统合综效"><a href="#习惯六：统合综效" class="headerlink" title="习惯六：统合综效"></a>习惯六：<strong>统合综效</strong></h2><p>重视不同个体的不同心理、情绪与智能，多学习与自己不同的观点。</p><h2 id="习惯七：不断更新自己"><a href="#习惯七：不断更新自己" class="headerlink" title="习惯七：不断更新自己"></a>习惯七：<strong>不断更新自己</strong></h2><p>在身体、精神、智力、社会情感四个大方面更新自己。</p>]]></content>
      
      
      <categories>
          
          <category> 阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高效能人士的七个习惯 </tag>
            
            <tag> 自我提升 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
